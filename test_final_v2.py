"""
RAG —Å–∏—Å—Ç–µ–º–∞ —á–µ—Ä–µ–∑ LangChain –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–µ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.

–ê–ª–≥–æ—Ä–∏—Ç–º:
1. –ü–æ–ª—É—á–∞–µ–º –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
2. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ —á–µ—Ä–µ–∑ GigaChat
3. –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –∏ –∏—â–µ–º –≤ OpenSearch (rag_descriptions)
4. –ë–µ—Ä–µ–º —Ç–æ–ø-k —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
5. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π –ø—Ä–∏–∑–Ω–∞–∫ —á–µ—Ä–µ–∑ GigaChat
6. –°–æ—Å—Ç–∞–≤–ª—è–µ–º SQL –∑–∞–ø—Ä–æ—Å –¥–ª—è –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
7. –ü–æ–¥–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏ —á–µ—Ä–µ–∑ GigaChat (—Ä–æ–ª—å: –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å)
"""

import logging
import pandas as pd
from typing import List, Dict, Optional, Tuple, Any
from langchain_core.documents import Document
from opensearchpy import OpenSearch
from gigachat import GigaChat
from sentence_transformers import SentenceTransformer
import duckdb
from prompts import (
    FEATURE_DESCRIPTION_PROMPT,
    FEATURE_MATCH_PROMPT,
    SQL_GENERATION_PROMPT,
    SQL_FIX_PROMPT,
    SQL_FIX_PROMPT_V2,
    FINAL_SUMMARY_PROMPT
)
GIGACHAT_CREDENTIALS = "MDE5OWUyNTAtNGNhZS03ZDdjLTg2ZmMtZjM5NDE0ZGFhNjUzOmYzMTk3ZWUyLTBlNTYtNDUzNy04ZWViLTUyZWU4ZjAyZGMzZA=="

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class RAGSystemLangChain:
    """
    RAG —Å–∏—Å—Ç–µ–º–∞ —á–µ—Ä–µ–∑ LangChain –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–µ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.
    """
    
    def __init__(
        self,
        opensearch_host: str = "localhost",
        opensearch_port: int = 9200,
        opensearch_use_ssl: bool = True,
        opensearch_verify_certs: bool = False,
        opensearch_auth: Optional[tuple] = None,
        opensearch_index_descriptions: str = "rag_descriptions",
        opensearch_index_layers: str = "rag_layers",
        embedding_model_name: str = "ai-forever/sbert_large_nlu_ru",
        credentials: str = GIGACHAT_CREDENTIALS
    ):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã.
        
        Args:
            opensearch_host: –•–æ—Å—Ç OpenSearch
            opensearch_port: –ü–æ—Ä—Ç OpenSearch
            opensearch_use_ssl: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å SSL
            opensearch_verify_certs: –ü—Ä–æ–≤–µ—Ä—è—Ç—å —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã
            opensearch_auth: –£—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (username, password)
            opensearch_index_descriptions: –ò–º—è –∏–Ω–¥–µ–∫—Å–∞ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (rag_descriptions)
            opensearch_index_layers: –ò–º—è –∏–Ω–¥–µ–∫—Å–∞ —Å –≥–µ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (rag_layers)
            embedding_model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            credentials: –£—á–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ GigaChat
        """
        self.credentials = credentials
        self.opensearch_index_descriptions = opensearch_index_descriptions
        self.opensearch_index_layers = opensearch_index_layers
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–∞ OpenSearch
        logger.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenSearch: {opensearch_host}:{opensearch_port} (SSL: {opensearch_use_ssl}, verify_certs: {opensearch_verify_certs})")
        
        # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∫–∞–∑–∞–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ SSL (SSL=True, verify_certs=False)
        self.opensearch_client = OpenSearch(
            hosts=[{'host': opensearch_host, 'port': opensearch_port}],
            http_auth=opensearch_auth,
            use_ssl=opensearch_use_ssl,
            verify_certs=opensearch_verify_certs,
            timeout=60,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç
            max_retries=5,  # –ë–æ–ª—å—à–µ –ø–æ–ø—ã—Ç–æ–∫
            retry_on_timeout=True,
            ssl_show_warn=False  # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è SSL
        )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏
        max_ping_attempts = 3
        ping_success = False
        for attempt in range(max_ping_attempts):
            try:
                if self.opensearch_client.ping():
                    ping_success = True
                    logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenSearch —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
                    break
                else:
                    logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_ping_attempts}: OpenSearch –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ ping")
            except Exception as ping_error:
                logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_ping_attempts}: –û—à–∏–±–∫–∞ ping - {type(ping_error).__name__}: {str(ping_error)[:100]}")
                if attempt < max_ping_attempts - 1:
                    import time
                    time.sleep(2)  # –ñ–¥–µ–º –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
        
        if not ping_success:
            logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ OpenSearch –ø–æ—Å–ª–µ –≤—Å–µ—Ö –ø–æ–ø—ã—Ç–æ–∫")
            logger.error("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ OpenSearch –∑–∞–ø—É—â–µ–Ω –∏ –¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–º –∞–¥—Ä–µ—Å–µ")
            logger.error("–°–∏—Å—Ç–µ–º–∞ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç —Ä–∞–±–æ—Ç—É, –Ω–æ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –±—É–¥–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∞")
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –ø–æ–ª—è –¥–ª—è –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ –æ–ø–∏—Å–∞–Ω–∏–π (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ)
        if ping_success:
            try:
                self.vector_field_name = self._get_vector_field_name(opensearch_index_descriptions)
                self.text_field_name = self._get_text_field_name(opensearch_index_descriptions)
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–æ–ª–µ–π: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
                self.vector_field_name = "embedding"
                self.text_field_name = "text"
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ
            self.vector_field_name = "embedding"
            self.text_field_name = "text"
            logger.warning("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –ø–æ–ª–µ–π –≤–µ–∫—Ç–æ—Ä–æ–≤ –∏ —Ç–µ–∫—Å—Ç–∞")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ–º SentenceTransformer –Ω–∞–ø—Ä—è–º—É—é)
        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {embedding_model_name}")
        self.embedding_model = SentenceTransformer(embedding_model_name)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ rag_layers –¥–ª—è SQL –∑–∞–ø—Ä–æ—Å–æ–≤ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ)
        if ping_success:
            try:
                logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ {opensearch_index_layers}...")
                self.df = self._load_all_documents_from_opensearch()
                logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.df)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, {len(self.df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ OpenSearch: {e}")
                self.df = pd.DataFrame()  # –ü—É—Å—Ç–æ–π DataFrame
        else:
            logger.warning("–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ OpenSearch - –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
            self.df = pd.DataFrame()  # –ü—É—Å—Ç–æ–π DataFrame
        
        logger.info("RAG —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    def _get_vector_field_name(self, index_name: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –ø–æ–ª—è –¥–ª—è –≤–µ–∫—Ç–æ—Ä–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ.
        
        Args:
            index_name: –ò–º—è –∏–Ω–¥–µ–∫—Å–∞
            
        Returns:
            –ò–º—è –ø–æ–ª—è –¥–ª—è –≤–µ–∫—Ç–æ—Ä–æ–≤
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º mapping –∏–Ω–¥–µ–∫—Å–∞
            mapping = self.opensearch_client.indices.get_mapping(index=index_name)
            index_mapping = mapping.get(index_name, {}).get('mappings', {}).get('properties', {})
            
            # –ò—â–µ–º –ø–æ–ª–µ —Ç–∏–ø–∞ knn_vector
            for field_name, field_props in index_mapping.items():
                if field_props.get('type') == 'knn_vector':
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–æ–≤: {field_name}")
                    return field_name
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø—Ä–æ–±—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∏–º–µ–Ω–∞
            for default_name in ['embedding', 'vector', 'vector_field', 'embedding_field']:
                if default_name in index_mapping:
                    logger.warning(f"–ü–æ–ª–µ {default_name} –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ –Ω–µ –∏–º–µ–µ—Ç —Ç–∏–ø knn_vector. –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ.")
                    return default_name
            
            logger.warning("–ü–æ–ª–µ –¥–ª—è –≤–µ–∫—Ç–æ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º 'embedding' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            return "embedding"
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –ø–æ–ª—è –¥–ª—è –≤–µ–∫—Ç–æ—Ä–æ–≤: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º 'embedding' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            return "embedding"
    
    def _get_text_field_name(self, index_name: str) -> str:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–Ω–∏ –ø–æ–ª—è –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –≤ –∏–Ω–¥–µ–∫—Å–µ.
        
        Args:
            index_name: –ò–º—è –∏–Ω–¥–µ–∫—Å–∞
            
        Returns:
            –ò–º—è –ø–æ–ª—è –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º mapping –∏–Ω–¥–µ–∫—Å–∞
            mapping = self.opensearch_client.indices.get_mapping(index=index_name)
            index_mapping = mapping.get(index_name, {}).get('mappings', {}).get('properties', {})
            
            # –ò—â–µ–º –ø–æ–ª–µ —Ç–∏–ø–∞ text
            for field_name, field_props in index_mapping.items():
                if field_props.get('type') == 'text':
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ: {field_name}")
                    return field_name
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∏–º—è
            logger.warning("–¢–µ–∫—Å—Ç–æ–≤–æ–µ –ø–æ–ª–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º 'text' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            return "text"
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—è: {e}. –ò—Å–ø–æ–ª—å–∑—É–µ–º 'text' –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
            return "text"
    
    def _load_all_documents_from_opensearch(self) -> pd.DataFrame:
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ rag_layers –≤ DataFrame.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç scroll API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
        
        Returns:
            DataFrame —Å–æ –≤—Å–µ–º–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞
        """
        logger.info(f"–ù–∞—á–∞–ª–æ –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ –∏–Ω–¥–µ–∫—Å–∞ {self.opensearch_index_layers}...")
        
        all_documents = []
        scroll_size = 1000  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è scroll
        
        try:
            # –ù–∞—á–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Å scroll
            response = self.opensearch_client.search(
                index=self.opensearch_index_layers,
                body={
                    "query": {"match_all": {}},
                    "size": scroll_size 
                },
                scroll='5m'  # –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ scroll –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            )
            
            scroll_id = response.get('_scroll_id')
            hits = response['hits']['hits']
            total_hits = response['hits']['total']
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ total (–º–æ–∂–µ—Ç –±—ã—Ç—å int –∏–ª–∏ dict —Å value)
            if isinstance(total_hits, dict):
                total_count = total_hits.get('value', 0)
            else:
                total_count = total_hits
            
            logger.info(f"–í—Å–µ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ: {total_count}")
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–≤–æ–π –ø–∞—Ä—Ç–∏–∏
            for hit in hits:
                source = hit['_source']
                # –î–æ–±–∞–≤–ª—è–µ–º _id –≤ –¥–æ–∫—É–º–µ–Ω—Ç
                source['_id'] = hit['_id']
                all_documents.append(source)
            
            processed = len(hits)
            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {processed}/{total_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
            
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º scroll –ø–æ–∫–∞ –µ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            while len(hits) > 0:
                response = self.opensearch_client.scroll(
                    scroll_id=scroll_id,
                    scroll='5m'
                )
                
                scroll_id = response.get('_scroll_id')
                hits = response['hits']['hits']
                
                for hit in hits:
                    source = hit['_source']
                    source['_id'] = hit['_id']
                    all_documents.append(source)
                
                processed += len(hits)
                if processed % 5000 == 0:
                    logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {processed}/{total_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...")
            
            # –û—á–∏—Å—Ç–∫–∞ scroll –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            if scroll_id:
                try:
                    self.opensearch_client.clear_scroll(scroll_id=scroll_id)
                except:
                    pass
            
            logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(all_documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ DataFrame
            if all_documents:
                df = pd.DataFrame(all_documents)
                logger.info(f"DataFrame —Å–æ–∑–¥–∞–Ω: {len(df)} —Å—Ç—Ä–æ–∫, {len(df.columns)} –∫–æ–ª–æ–Ω–æ–∫")
                return df
            else:
                logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∏–Ω–¥–µ–∫—Å–µ")
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ OpenSearch: {e}")
            raise
    
    def generate_feature_description(self, user_query: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏–ª–∏ –æ–±—â–µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ GigaChat.
        
        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏–ª–∏ –∑–∞–ø—Ä–æ—Å–∞
        """
        logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {user_query}")
        
        prompt = FEATURE_DESCRIPTION_PROMPT.format(user_query=user_query)
        
        try:
            with GigaChat(
                credentials=self.credentials,
                verify_ssl_certs=False,
                scope='GIGACHAT_API_B2B',
                model='GigaChat-2-Pro'
            ) as giga:
                response = giga.chat(prompt)
                description = response.choices[0].message.content.strip()
                logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –æ–ø–∏—Å–∞–Ω–∏–µ: {description[:100]}...")
                return description
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–∏–µ
            return user_query
    
    def search_in_opensearch(self, query: str, top_k: int = 10) -> List[Document]:
        """
        –ü–æ–∏—Å–∫ –≤ OpenSearch –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–º—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é (–ø—Ä—è–º–æ–π KNN –ø–æ–∏—Å–∫ –±–µ–∑ LangChain).
        
        Args:
            query: –¢–µ–∫—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        """
        logger.info(f"–ü–æ–∏—Å–∫ –≤ OpenSearch: '{query[:50]}...' (—Ç–æ–ø-{top_k})")
        
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞
            query_embedding = self.embedding_model.encode(query).tolist()
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º KNN –∑–∞–ø—Ä–æ—Å –¥–ª—è OpenSearch
            # –ü—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç: KNN –≤–Ω—É—Ç—Ä–∏ query
            knn_query = {
                "size": top_k,
                "query": {
                    "knn": {
                        self.vector_field_name: {
                            "vector": query_embedding,
                            "k": top_k
                        }
                    }
                }
            }
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            response = self.opensearch_client.search(
                index=self.opensearch_index_descriptions,
                body=knn_query
            )
            
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Document –æ–±—ä–µ–∫—Ç—ã
            documents = []
            for hit in response['hits']['hits']:
                source = hit['_source']
                text = source.get(self.text_field_name, '')
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–≤—Å–µ –ø–æ–ª—è –∫—Ä–æ–º–µ —Ç–µ–∫—Å—Ç–∞ –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞)
                metadata = {k: v for k, v in source.items() 
                           if k != self.text_field_name and k != self.vector_field_name}
                metadata['_id'] = hit['_id']
                metadata['_score'] = hit['_score']
                
                doc = Document(page_content=text, metadata=metadata)
                documents.append(doc)
            
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
            return documents
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –≤ OpenSearch: {e}")
            return []
    
    def check_feature_match(self, user_query: str, feature_name: str, feature_description: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ –ø—Ä–∏–∑–Ω–∞–∫ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        Args:
            user_query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            feature_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞
            feature_description: –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞
            
        Returns:
            True –µ—Å–ª–∏ –ø—Ä–∏–∑–Ω–∞–∫ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç, False –∏–Ω–∞—á–µ
        """
        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞ '{feature_name}' –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
        
        prompt = FEATURE_MATCH_PROMPT.format(
            user_query=user_query,
            feature_name=feature_name,
            feature_description=feature_description
        )
        
        try:
            with GigaChat(
                credentials=self.credentials,
                verify_ssl_certs=False,
                scope='GIGACHAT_API_B2B',
                model='GigaChat-2-Pro'
            ) as giga:
                response = giga.chat(prompt)
                answer = response.choices[0].message.content.strip().upper()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
                if "–î–ê" in answer or "YES" in answer:
                    logger.info(f"–ü—Ä–∏–∑–Ω–∞–∫ '{feature_name}' —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–ø—Ä–æ—Å—É")
                    return True
                else:
                    logger.info(f"–ü—Ä–∏–∑–Ω–∞–∫ '{feature_name}' –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∑–∞–ø—Ä–æ—Å—É")
                    return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –ø—Ä–∏–∑–Ω–∞–∫ –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç
            return False
    
    def get_columns_info(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∫–æ–ª–æ–Ω–∫–∞—Ö –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞."""
        columns_info = []
        for col in self.df.columns:
            dtype = str(self.df[col].dtype)
            non_null_count = self.df[col].notna().sum()
            columns_info.append(f"- `{col}` ({dtype}, –∑–∞–ø–æ–ª–Ω–µ–Ω–æ: {non_null_count}/{len(self.df)})")
        return "\n".join(columns_info)
    
    def generate_sql_query(
        self,
        user_query: str,
        feature_name: str,
        feature_description: str,
        max_attempts: int = 3
    ) -> Optional[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞ —Å —Ç—Ä–µ—Ö—Ñ–∞–∫—Ç–æ—Ä–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π.
        –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è —Å –æ—à–∏–±–∫–æ–π, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç—Å—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ.
        
        Args:
            user_query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            feature_name: –ù–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞
            feature_description: –û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞
            max_attempts: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3)
            
        Returns:
            SQL –∑–∞–ø—Ä–æ—Å –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        """
        logger.info(f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–∞ '{feature_name}' (–º–∞–∫—Å–∏–º—É–º {max_attempts} –ø–æ–ø—ã—Ç–æ–∫)")
        
        columns_info = self.get_columns_info()
        sql_query = None
        attempt = 0
        error_history = []  # –ò—Å—Ç–æ—Ä–∏—è –≤—Å–µ—Ö –æ—à–∏–±–æ–∫ –¥–ª—è —Ç—Ä–µ—Ç—å–µ–π –ø–æ–ø—ã—Ç–∫–∏
        all_candidate_bindings = []  # –í—Å–µ candidate bindings –∏–∑ –≤—Å–µ—Ö –æ—à–∏–±–æ–∫
        
        while attempt < max_attempts:
            attempt += 1
            logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts} –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL –∑–∞–ø—Ä–æ—Å–∞")
            
            try:
                if attempt == 1:
                    # –ü–µ—Ä–≤–∞—è –ø–æ–ø—ã—Ç–∫–∞ - –æ–±—ã—á–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
                    prompt = SQL_GENERATION_PROMPT.format(
                        user_query=user_query,
                        feature_name=feature_name,
                        feature_description=feature_description,
                        columns_info=columns_info
                    )
                elif attempt == 2:
                    # –í—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–∫–∏
                    error_msg = str(self.last_sql_error) if hasattr(self, 'last_sql_error') else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
                    candidate_bindings = getattr(self, 'last_candidate_bindings', [])
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ candidate bindings
                    unique_bindings = list(set(candidate_bindings))
                    candidate_bindings_text = "\n".join([f"- `{col}`" for col in unique_bindings]) if unique_bindings else "–ù–µ —É–∫–∞–∑–∞–Ω—ã"
                    prompt = SQL_FIX_PROMPT.format(
                        user_query=user_query,
                        feature_name=feature_name,
                        feature_description=feature_description,
                        columns_info=columns_info,
                        sql_query=sql_query or "",
                        error_message=error_msg,
                        candidate_bindings=candidate_bindings_text
                    )
                else:
                    # –¢—Ä–µ—Ç—å—è –ø–æ–ø—ã—Ç–∫–∞ - –≥–ª—É–±–æ–∫–æ–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –≤—Å–µ–π –∏—Å—Ç–æ—Ä–∏–∏ –æ—à–∏–±–æ–∫
                    error_msg = str(self.last_sql_error) if hasattr(self, 'last_sql_error') else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
                    error_history_text = "\n".join(error_history) if error_history else "–ò—Å—Ç–æ—Ä–∏—è –æ—à–∏–±–æ–∫ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ candidate bindings –∏–∑ –≤—Å–µ—Ö –æ—à–∏–±–æ–∫
                    if all_candidate_bindings:
                        unique_bindings = list(set(all_candidate_bindings))
                    else:
                        unique_bindings = list(set(getattr(self, 'last_candidate_bindings', [])))
                    candidate_bindings_text = "\n".join([f"- `{col}`" for col in unique_bindings]) if unique_bindings else "–ù–µ —É–∫–∞–∑–∞–Ω—ã"
                    prompt = SQL_FIX_PROMPT_V2.format(
                        user_query=user_query,
                        feature_name=feature_name,
                        feature_description=feature_description,
                        columns_info=columns_info,
                        sql_query=sql_query or "",
                        error_message=error_msg,
                        error_history=error_history_text,
                        candidate_bindings=candidate_bindings_text
                    )
                
                with GigaChat(
                    credentials=self.credentials,
                    verify_ssl_certs=False,
                    scope='GIGACHAT_API_B2B',
                    model='GigaChat-2-Pro'
                ) as giga:
                    response = giga.chat(prompt)
                    sql_query = response.choices[0].message.content.strip()
                    
                    # –û—á–∏—Å—Ç–∫–∞ SQL –∑–∞–ø—Ä–æ—Å–∞ –æ—Ç markdown —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è, –µ—Å–ª–∏ –µ—Å—Ç—å
                    if sql_query.startswith("```sql"):
                        sql_query = sql_query[6:]
                    if sql_query.startswith("```"):
                        sql_query = sql_query[3:]
                    if sql_query.endswith("```"):
                        sql_query = sql_query[:-3]
                    sql_query = sql_query.strip()
                    
                    logger.info(f"–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω SQL –∑–∞–ø—Ä–æ—Å (–ø–æ–ø—ã—Ç–∫–∞ {attempt}): {sql_query[:100]}...")
                    
                    # –ü—Ä–æ–±—É–µ–º –≤—ã–ø–æ–ª–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
                    try:
                        test_result = self.execute_sql_query(sql_query, test_mode=True)
                        
                        if test_result is not None:
                            # –ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–∏–ª—Å—è —É—Å–ø–µ—à–Ω–æ
                            logger.info(f"SQL –∑–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–≤–µ—Ä–µ–Ω –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt}")
                            return sql_query
                        else:
                            # –ó–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–æ–ø—ã—Ç–∫–∏
                            if attempt < max_attempts:
                                error_msg = str(self.last_sql_error) if hasattr(self, 'last_sql_error') else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"
                                error_history.append(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt}: {error_msg}")
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º candidate bindings –∏–∑ —Ç–µ–∫—É—â–µ–π –æ—à–∏–±–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
                                if hasattr(self, 'last_candidate_bindings') and self.last_candidate_bindings:
                                    all_candidate_bindings.extend(self.last_candidate_bindings)
                                    error_history.append(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(self.last_candidate_bindings)}")
                                logger.warning(f"SQL –∑–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π: {error_msg[:200]}... –ü—Ä–æ–±—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts})")
                                continue
                            else:
                                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π SQL –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫")
                                return None
                    except Exception as test_error:
                        # –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∑–∞–ø—Ä–æ—Å–∞
                        self.last_sql_error = test_error
                        if attempt < max_attempts:
                            error_msg = str(test_error)
                            error_history.append(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt}: {error_msg}")
                            # –ò–∑–≤–ª–µ–∫–∞–µ–º candidate bindings –∏–∑ –æ—à–∏–±–∫–∏
                            candidate_bindings = self._extract_candidate_bindings(error_msg)
                            if candidate_bindings:
                                self.last_candidate_bindings = candidate_bindings
                                all_candidate_bindings.extend(candidate_bindings)
                                error_history.append(f"–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(candidate_bindings)}")
                                logger.info(f"–ù–∞–π–¥–µ–Ω—ã –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –æ—à–∏–±–∫–µ: {candidate_bindings}")
                            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ SQL –∑–∞–ø—Ä–æ—Å–∞: {test_error}. –ü—Ä–æ–±—É–µ–º –∏—Å–ø—Ä–∞–≤–∏—Ç—å (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts})")
                            continue
                        else:
                            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π SQL –∑–∞–ø—Ä–æ—Å –ø–æ—Å–ª–µ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫")
                            return None
                            
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ SQL –∑–∞–ø—Ä–æ—Å–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt}: {e}")
                if attempt >= max_attempts:
                    return None
                continue
        
        return sql_query
    
    def _extract_candidate_bindings(self, error_msg: str) -> List[str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç candidate bindings –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏—è –æ–± –æ—à–∏–±–∫–µ DuckDB.
        
        Args:
            error_msg: –°–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–º–µ–Ω –∫–æ–ª–æ–Ω–æ–∫ –∏–∑ –æ—à–∏–±–∫–∏
        """
        import re
        candidate_bindings = []
        
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω "Candidate bindings: ..."
        match = re.search(r'Candidate bindings:\s*([^\n]+)', error_msg)
        if match:
            bindings_str = match.group(1)
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º–µ–Ω–∞ –≤ –∫–∞–≤—ã—á–∫–∞—Ö
            bindings = re.findall(r'"([^"]+)"', bindings_str)
            candidate_bindings.extend(bindings)
        
        return candidate_bindings
    
    def execute_sql_query(self, sql_query: str, test_mode: bool = False) -> Optional[pd.DataFrame]:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ DuckDB.
        
        Args:
            sql_query: SQL –∑–∞–ø—Ä–æ—Å
            test_mode: –ï—Å–ª–∏ True, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –æ—à–∏–±–∫—É –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            
        Returns:
            DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏–ª–∏ None –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ (–≤ test_mode)
        """
        logger.info(f"–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL –∑–∞–ø—Ä–æ—Å–∞: {sql_query[:100]}...")
        
        try:
            # –°–æ–∑–¥–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å DuckDB
            conn = duckdb.connect()
            
            # –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º DataFrame –∫–∞–∫ —Ç–∞–±–ª–∏—Ü—É
            conn.register('df', self.df)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
            result = conn.execute(sql_query).fetchdf()
            
            conn.close()
            
            logger.info(f"SQL –∑–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω, –Ω–∞–π–¥–µ–Ω–æ {len(result)} —Å—Ç—Ä–æ–∫")
            return result
        except Exception as e:
            error_msg = str(e)
            logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è SQL –∑–∞–ø—Ä–æ—Å–∞: {error_msg}")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
            if test_mode:
                self.last_sql_error = e
                # –ò–∑–≤–ª–µ–∫–∞–µ–º candidate bindings –∏–∑ –æ—à–∏–±–∫–∏
                candidate_bindings = self._extract_candidate_bindings(error_msg)
                if candidate_bindings:
                    self.last_candidate_bindings = candidate_bindings
                    logger.info(f"–ù–∞–π–¥–µ–Ω—ã –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –≤ –æ—à–∏–±–∫–µ: {candidate_bindings}")
                return None
            else:
                return pd.DataFrame()
    
    def generate_final_summary(
        self,
        user_query: str,
        results_df: pd.DataFrame
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ GigaChat (—Ä–æ–ª—å: –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å).
        
        Args:
            user_query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            results_df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞
            
        Returns:
            –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è
        """
        logger.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è")
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
        if results_df.empty:
            retrieved_data = "–î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –±–∞–∑–µ."
            coordinates_section = ""
        else:
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ (–ø–µ—Ä–≤—ã–µ 10 –∑–∞–ø–∏—Å–µ–π)
            # –ù–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–∑ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –∫–∞—Ä—Ç–µ
            max_rows_for_prompt = 10
            total_results = len(results_df)
            if total_results > max_rows_for_prompt:
                retrieved_data = f"–ù–∞–π–¥–µ–Ω–æ {total_results} –∑–∞–ø–∏—Å–µ–π. –ü–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ {max_rows_for_prompt}:\n\n"
                retrieved_data += results_df.head(max_rows_for_prompt).to_string(index=False)
            else:
                retrieved_data = results_df.to_string(index=False)
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏–∑ –í–°–ï–• —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –∫–∞—Ä—Ç–µ)
            coordinates_list = []
            if 'lon' in results_df.columns and 'lat' in results_df.columns:
                for idx, row in results_df.iterrows():
                    lon = row.get('lon', None)
                    lat = row.get('lat', None)
                    
                    if pd.notna(lon) and pd.notna(lat):
                        lon_str = str(lon).strip()
                        lat_str = str(lat).strip()
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å—Å–∏–≤–æ–≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                        if lon_str.startswith('['):
                            try:
                                import ast
                                lon_array = ast.literal_eval(lon_str)
                                if isinstance(lon_array, list) and len(lon_array) > 0:
                                    lon_str = str(lon_array[0])
                            except:
                                lon_str = lon_str.strip('[]').split(',')[0].strip()
                        
                        if lat_str.startswith('['):
                            try:
                                import ast
                                lat_array = ast.literal_eval(lat_str)
                                if isinstance(lat_array, list) and len(lat_array) > 0:
                                    lat_str = str(lat_array[-1]) if len(lat_array) > 1 else str(lat_array[0])
                            except:
                                lat_str = lat_str.strip('[]').split(',')[-1].strip()
                        
                        if lon_str and lat_str and lon_str not in ['nan', 'None'] and lat_str not in ['nan', 'None']:
                            coordinates_list.append(f"–ó–∞–ø–∏—Å—å {idx + 1}: –î–æ–ª–≥–æ—Ç–∞: {lon_str}, –®–∏—Ä–æ—Ç–∞: {lat_str}")
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–µ–∫—Ü–∏—é —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ (–≤—Å–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã, –Ω–µ —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10)
            # –ù–æ –≤ —Ç–µ–∫—Å—Ç–µ —É–∫–∞–∑—ã–≤–∞–µ–º, —á—Ç–æ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞ –ø–æ–∫–∞–∑–∞–Ω—ã —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 10 –∑–∞–ø–∏—Å–µ–π
            if coordinates_list:
                coords_text = "\n".join(coordinates_list)
                if total_results > max_rows_for_prompt:
                    coords_text = f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {total_results} –∑–∞–ø–∏—Å–µ–π —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏. –í –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø–æ–∫–∞–∑–∞–Ω—ã –ø–µ—Ä–≤—ã–µ {max_rows_for_prompt} –∑–∞–ø–∏—Å–µ–π, –Ω–æ –≤—Å–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ –∫–∞—Ä—Ç–µ.\n\n" + coords_text
                coordinates_section = "\n\n" + "="*60 + "\n–ö–û–û–†–î–ò–ù–ê–¢–´ –ù–ê–ô–î–ï–ù–ù–´–• –ó–ê–ü–ò–°–ï–ô:\n" + "="*60 + "\n" + coords_text + "\n" + "="*60
            else:
                coordinates_section = "\n\n‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –¥–∞–Ω–Ω—ã—Ö."
        
        prompt = FINAL_SUMMARY_PROMPT.format(
            user_query=user_query,
            retrieved_data=retrieved_data,
            coordinates_section=coordinates_section
        )
        
        try:
            with GigaChat(
                credentials=self.credentials,
                verify_ssl_certs=False,
                scope='GIGACHAT_API_B2B',
                model='GigaChat-2-Pro'
            ) as giga:
                response = giga.chat(prompt)
                summary = response.choices[0].message.content.strip()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤–∫–ª—é—á–µ–Ω—ã –≤ –æ—Ç–≤–µ—Ç
                if coordinates_section and '–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç' not in summary.lower() and 'üìç' not in summary:
                    logger.warning("–ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–µ –≤–∫–ª—é—á–µ–Ω—ã –≤ –æ—Ç–≤–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ")
                    coords_text = "\n\nüìç –ö–û–û–†–î–ò–ù–ê–¢–´ –ù–ê–ô–î–ï–ù–ù–´–• –ó–ê–ü–ò–°–ï–ô:\n" + "\n".join([line.replace("–ó–∞–ø–∏—Å—å ", "‚Ä¢ ") for line in coordinates_list])
                    summary += coords_text
                
                logger.info("–§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω")
                return summary
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—ã–π –æ—Ç–≤–µ—Ç —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏
            if results_df.empty:
                return "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã."
            else:
                fallback = f"–ù–∞–π–¥–µ–Ω–æ {len(results_df)} –∑–∞–ø–∏—Å–µ–π:\n\n{retrieved_data}"
                if coordinates_section:
                    fallback += coordinates_section
                return fallback
    
    def query(
        self,
        user_query: str,
        top_k: int = 10
    ) -> Tuple[pd.DataFrame, str]:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ RAG –∑–∞–ø—Ä–æ—Å–∞.
        
        Args:
            user_query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–ø —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ OpenSearch
            
        Returns:
            Tuple[DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏, –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç]
        """
        logger.info(f"\n{'='*80}")
        logger.info(f"RAG –ó–ê–ü–†–û–°: {user_query}")
        logger.info(f"{'='*80}\n")
        
        # –®–∞–≥ 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞ –∏–ª–∏ –∑–∞–ø—Ä–æ—Å–∞
        logger.info("–®–ê–ì 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–∞/–∑–∞–ø—Ä–æ—Å–∞")
        feature_description = self.generate_feature_description(user_query)
        
        # –®–∞–≥ 2: –ü–æ–∏—Å–∫ –≤ OpenSearch
        logger.info(f"–®–ê–ì 2: –ü–æ–∏—Å–∫ –≤ OpenSearch (—Ç–æ–ø-{top_k})")
        search_results = self.search_in_opensearch(feature_description, top_k=top_k)
        
        if not search_results:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ OpenSearch")
            return pd.DataFrame(), "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –≤ –±–∞–∑–µ."
        
        # –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
        logger.info(f"–®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ {len(search_results)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        matched_features = []
        
        for doc in search_results:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º feature_name –∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            # –í –∏–Ω–¥–µ–∫—Å–µ rag_descriptions –ø–æ–ª–µ feature_name —Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            feature_name = doc.metadata.get('feature_name', '')
            
            # –ï—Å–ª–∏ –Ω–µ—Ç –≤ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ –¥—Ä—É–≥–∏—Ö –ø–æ–ª–µ–π
            if not feature_name:
                # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ–ª—è
                feature_name = doc.metadata.get('name', '')
                if not feature_name:
                    # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –≤ page_content (–æ–ø–∏—Å–∞–Ω–∏–µ –º–æ–∂–µ—Ç –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å –Ω–∞–∑–≤–∞–Ω–∏—è)
                    text = doc.page_content or ""
                    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –∏–ª–∏ –±–µ—Ä–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
                    parts = text.split('\n')
                    for part in parts[:3]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ 3 —Å—Ç—Ä–æ–∫–∏
                        part = part.strip()
                        if part and len(part) < 100:  # –ù–∞–∑–≤–∞–Ω–∏–µ –æ–±—ã—á–Ω–æ –∫–æ—Ä–æ—Ç–∫–æ–µ
                            feature_name = part
                            break
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ
            feature_desc = doc.page_content if doc.page_content else ""
            if not feature_desc:
                feature_desc = doc.metadata.get('description', '')
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
            feature_desc = feature_desc[:1000] if feature_desc else ""
            
            if not feature_name:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å feature_name –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞. –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {doc.metadata.keys()}")
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∞ –∑–∞–ø—Ä–æ—Å—É
            if self.check_feature_match(user_query, feature_name, feature_desc):
                matched_features.append({
                    'feature_name': feature_name,
                    'description': feature_desc,
                    'doc': doc
                })
        
        if not matched_features:
            logger.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å—É")
            return pd.DataFrame(), "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É."
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(matched_features)} —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        
        # –®–∞–≥ 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL –∑–∞–ø—Ä–æ—Å–æ–≤
        logger.info("–®–ê–ì 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL –∑–∞–ø—Ä–æ—Å–æ–≤")
        all_results = []
        
        for feature_info in matched_features:
            feature_name = feature_info['feature_name']
            feature_desc = feature_info['description']
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º SQL –∑–∞–ø—Ä–æ—Å
            sql_query = self.generate_sql_query(user_query, feature_name, feature_desc)
            
            if sql_query:
                # –í—ã–ø–æ–ª–Ω—è–µ–º SQL –∑–∞–ø—Ä–æ—Å
                result_df = self.execute_sql_query(sql_query)
                
                if not result_df.empty:
                    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–∑–Ω–∞–∫–µ
                    result_df['matched_feature'] = feature_name
                    all_results.append(result_df)
                    logger.info(f"–î–ª—è –ø—Ä–∏–∑–Ω–∞–∫–∞ '{feature_name}' –Ω–∞–π–¥–µ–Ω–æ {len(result_df)} –∑–∞–ø–∏—Å–µ–π")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if all_results:
            combined_results = pd.concat(all_results, ignore_index=True)
            logger.info(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(combined_results)} –∑–∞–ø–∏—Å–µ–π")
        else:
            combined_results = pd.DataFrame()
            logger.warning("SQL –∑–∞–ø—Ä–æ—Å—ã –Ω–µ –≤–µ—Ä–Ω—É–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        
        # –®–∞–≥ 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞
        logger.info("–®–ê–ì 5: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—è")
        final_answer = self.generate_final_summary(user_query, combined_results)
        
        return combined_results, final_answer
    
    def extract_coordinates(self, results_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –¥–ª—è –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞.
        
        Args:
            results_df: DataFrame —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –ø–æ–∏—Å–∫–∞
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏: [{"lon": float, "lat": float, "info": str}, ...]
        """
        coordinates = []
        
        if results_df.empty:
            return coordinates
        
        if 'lon' in results_df.columns and 'lat' in results_df.columns:
            for idx, row in results_df.iterrows():
                lon = row.get('lon', None)
                lat = row.get('lat', None)
                
                if pd.notna(lon) and pd.notna(lat):
                    lon_str = str(lon).strip()
                    lat_str = str(lat).strip()
                    
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–∞—Å—Å–∏–≤–æ–≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                    if lon_str.startswith('['):
                        try:
                            import ast
                            lon_array = ast.literal_eval(lon_str)
                            if isinstance(lon_array, list) and len(lon_array) > 0:
                                lon_val = float(lon_array[0])
                            else:
                                continue
                        except:
                            try:
                                lon_val = float(lon_str.strip('[]').split(',')[0].strip())
                            except:
                                continue
                    else:
                        try:
                            lon_val = float(lon_str)
                        except:
                            continue
                    
                    if lat_str.startswith('['):
                        try:
                            import ast
                            lat_array = ast.literal_eval(lat_str)
                            if isinstance(lat_array, list) and len(lat_array) > 0:
                                lat_val = float(lat_array[-1] if len(lat_array) > 1 else lat_array[0])
                            else:
                                continue
                        except:
                            try:
                                lat_val = float(lat_str.strip('[]').split(',')[-1].strip())
                            except:
                                continue
                    else:
                        try:
                            lat_val = float(lat_str)
                        except:
                            continue
                    
                    # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
                    if -180 <= lon_val <= 180 and -90 <= lat_val <= 90:
                        # –°–æ–±–∏—Ä–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–ø–∏—Å–∏
                        info_parts = []
                        for col in ['layer_name', '–†–µ–≥–∏–æ–Ω', '–°–≤–∏—Ç–∞', '–ü–ª–∞—Å—Ç', 'matched_feature']:
                            if col in row and pd.notna(row[col]):
                                info_parts.append(f"{col}: {row[col]}")
                        
                        info = ", ".join(info_parts) if info_parts else f"–ó–∞–ø–∏—Å—å {idx + 1}"
                        
                        coordinates.append({
                            "lon": lon_val,
                            "lat": lat_val,
                            "info": info
                        })
        
        return coordinates


def main():
    """–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è RAG —Å–∏—Å—Ç–µ–º—ã."""
    
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    OPENSEARCH_HOST="155.212.191.208"
    OPENSEARCH_PORT=9200
    OPENSEARCH_USE_SSL=False  
    OPENSEARCH_VERIFY_CERTS=False
    OPENSEARCH_AUTH = ("admin", "admin")
    OPENSEARCH_INDEX_DESCRIPTIONS = "rag_descriptions"
    OPENSEARCH_INDEX_LAYERS = "rag_layers"
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã...")
    rag_system = RAGSystemLangChain(
        opensearch_host=OPENSEARCH_HOST,
        opensearch_port=OPENSEARCH_PORT,
        opensearch_use_ssl=OPENSEARCH_USE_SSL,
        opensearch_verify_certs=OPENSEARCH_VERIFY_CERTS,
        opensearch_auth=OPENSEARCH_AUTH,
        opensearch_index_descriptions=OPENSEARCH_INDEX_DESCRIPTIONS,
        opensearch_index_layers=OPENSEARCH_INDEX_LAYERS,
        credentials=GIGACHAT_CREDENTIALS
    )
    
    # –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤
    test_queries = [
        "–ì–¥–µ R0 –±–æ–ª—å—à–µ 1.0%?"
        #"–ì–¥–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –°–æ—Ä–≥?"
    ]
    
    # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–æ–≤
    for query in test_queries:
        logger.info(f"\n{'='*80}")
        logger.info(f"–û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–ü–†–û–°–ê: {query}")
        logger.info(f"{'='*80}\n")
        
        try:
            results, answer = rag_system.query(user_query=query, top_k=20)
            
            # –í—ã–≤–æ–¥ –æ—Ç–≤–µ—Ç–∞
            print("\n" + "="*80)
            print("–û–¢–í–ï–¢ –ü–†–ï–ü–û–î–ê–í–ê–¢–ï–õ–Ø:")
            print("="*80)
            print(answer)
            print("="*80 + "\n")
            
            # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            if not results.empty:
                print(f"–ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {len(results)}")
                print(f"–ö–æ–ª–æ–Ω–∫–∏: {list(results.columns)[:10]}...")
            else:
                print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ '{query}': {e}", exc_info=True)


if __name__ == "__main__":
    main()

